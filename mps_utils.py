#!/usr/bin/env python3
"""
MPS (Metal Performance Shaders) ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ

Apple Silicon Macì—ì„œ PyTorch MPS ë””ë°”ì´ìŠ¤ì˜ ì„±ëŠ¥ì„ ìµœì í™”í•˜ê¸° ìœ„í•œ
warm-up ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import time
import torch


def warm_up_mps():
    """
    MPS ë””ë°”ì´ìŠ¤ warm-upì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Apple Silicon Macì˜ MPS ë””ë°”ì´ìŠ¤ ì„±ëŠ¥ì„ ìµœì í™”í•˜ê¸° ìœ„í•´
    ë‹¤ì–‘í•œ í¬ê¸°ì˜ í…ì„œ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ì—¬ GPUë¥¼ ì¤€ë¹„ì‹œí‚µë‹ˆë‹¤.

    Returns:
        bool: MPS ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
    """
    print("ğŸ”¥ MPS ë””ë°”ì´ìŠ¤ warm-up ì¤‘...")

    # MPS ë””ë°”ì´ìŠ¤ í™•ì¸
    if not torch.backends.mps.is_available():
        print("âš ï¸  MPSë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return False

    device = "mps"
    start_time = time.time()

    print("   - 1ë‹¨ê³„: ê¸°ë³¸ ì—°ì‚° warm-up...")
    # 1ë‹¨ê³„: ê¸°ë³¸ ì—°ì‚° warm-up (500íšŒ)
    for i in range(500):
        dummy_tensor1 = torch.rand(1000, 1000).to(device)
        dummy_tensor2 = torch.rand(1000, 1000).to(device)
        torch.matmul(dummy_tensor1, dummy_tensor2)

        if i % 50 == 0:
            print(f"     ì§„í–‰ë¥ : {i+1}/500")

    print("   - 2ë‹¨ê³„: ëŒ€ìš©ëŸ‰ ì—°ì‚° warm-up...")
    # 2ë‹¨ê³„: ëŒ€ìš©ëŸ‰ ì—°ì‚° warm-up (100íšŒ)
    for i in range(100):
        dummy_tensor3 = torch.rand(3000, 3000).to(device)
        dummy_tensor4 = torch.rand(3000, 3000).to(device)
        torch.matmul(dummy_tensor3, dummy_tensor4)

        if i % 10 == 0:
            print(f"     ì§„í–‰ë¥ : {i+1}/100")

    print("   - 3ë‹¨ê³„: ë³µí•© ì—°ì‚° warm-up...")
    # 3ë‹¨ê³„: ë³µí•© ì—°ì‚° warm-up (50íšŒ)
    for i in range(50):
        # ë‹¤ì–‘í•œ ì—°ì‚° ì¡°í•©
        x = torch.rand(2000, 2000).to(device)
        y = torch.rand(2000, 2000).to(device)

        # í–‰ë ¬ ê³±ì…ˆ
        result1 = torch.matmul(x, y)
        # ì „ì¹˜ í–‰ë ¬
        result2 = torch.matmul(x.t(), y)
        # ìš”ì†Œë³„ ê³±ì…ˆ
        result3 = x * y
        # í•©ê³„
        result4 = torch.sum(result1 + result2 + result3)
        # ì¶”ê°€ ì—°ì‚°ë“¤
        result5 = torch.relu(result4)
        result6 = torch.softmax(result1, dim=1)
        result7 = torch.mean(result6)

        if i % 10 == 0:
            print(f"     ì§„í–‰ë¥ : {i+1}/50")

    print("   - 4ë‹¨ê³„: ê·¹ëŒ€ìš©ëŸ‰ ì—°ì‚° warm-up...")
    # 4ë‹¨ê³„: ê·¹ëŒ€ìš©ëŸ‰ ì—°ì‚° warm-up (20íšŒ)
    for i in range(20):
        # M4 Proì˜ ë©”ëª¨ë¦¬ í•œê³„ê¹Œì§€ í™œìš©
        dummy_tensor5 = torch.rand(4000, 4000).to(device)
        dummy_tensor6 = torch.rand(4000, 4000).to(device)
        torch.matmul(dummy_tensor5, dummy_tensor6)

        if i % 5 == 0:
            print(f"     ì§„í–‰ë¥ : {i+1}/20")

    end_time = time.time()
    print(f"âœ… MPS warm-up ì™„ë£Œ! ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    print(f"   - ì´ ì—°ì‚°: 670íšŒ (ê¸°ë³¸ 500íšŒ + ëŒ€ìš©ëŸ‰ 100íšŒ + ë³µí•© 50íšŒ + ê·¹ëŒ€ìš©ëŸ‰ 20íšŒ)")
    print(f"   - ìµœëŒ€ í…ì„œ í¬ê¸°: 4000x4000")
    print(f"   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ìµœëŒ€ ~128GB (4000x4000x4ë°”ì´íŠ¸x2)")

    return True


def check_mps_availability():
    """
    MPS ë””ë°”ì´ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

    Returns:
        dict: MPS ìƒíƒœ ì •ë³´
            - available: MPS ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
            - device: ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ ('mps' ë˜ëŠ” 'cpu')
            - message: ìƒíƒœ ë©”ì‹œì§€
    """
    if torch.backends.mps.is_available():
        return {
            'available': True,
            'device': 'mps',
            'message': 'MPS ë””ë°”ì´ìŠ¤ ì‚¬ìš© ê°€ëŠ¥'
        }
    else:
        return {
            'available': False,
            'device': 'cpu',
            'message': 'MPS ë””ë°”ì´ìŠ¤ ì‚¬ìš© ë¶ˆê°€ - CPU ì‚¬ìš©'
        }


def get_optimal_device():
    """
    ìµœì ì˜ ë””ë°”ì´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Returns:
        str: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('mps' ë˜ëŠ” 'cpu')
    """
    if torch.backends.mps.is_available():
        return 'mps'
    else:
        return 'cpu'


def print_device_info():
    """
    í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    print("ğŸ” ë””ë°”ì´ìŠ¤ ì •ë³´:")
    print("=" * 40)

    # PyTorch ë²„ì „
    print(f"PyTorch ë²„ì „: {torch.__version__}")

    # MPS ìƒíƒœ
    mps_status = check_mps_availability()
    print(f"MPS ìƒíƒœ: {mps_status['message']}")

    # CPU ì •ë³´
    print(f"CPU ì½”ì–´ ìˆ˜: {torch.get_num_threads()}")

    # ê¶Œì¥ ë””ë°”ì´ìŠ¤
    optimal_device = get_optimal_device()
    print(f"ê¶Œì¥ ë””ë°”ì´ìŠ¤: {optimal_device}")

    print("=" * 40)


if __name__ == "__main__":
    # ëª¨ë“ˆì„ ì§ì ‘ ì‹¤í–‰í•  ë•Œì˜ í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸš€ MPS Utils ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print_device_info()

    if torch.backends.mps.is_available():
        warm_up_mps()
    else:
        print("MPSë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ warm-upì„ ê±´ë„ˆëœë‹ˆë‹¤.")
