#!/usr/bin/env python3
"""
ì €ì¥ëœ íŒŒì¸íŠœë‹ ëª¨ë¸ ì‚¬ìš© ì˜ˆì‹œ

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” 12_bert.pyë¡œ í•™ìŠµí•œ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬
ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import os
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from mps_utils import get_optimal_device


def load_saved_model(model_path: str):
    """ì €ì¥ëœ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    print(f"ğŸ“‚ ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")

    try:
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSequenceClassification.from_pretrained(model_path)

        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        return tokenizer, model
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None


def predict_sentiment(text: str, tokenizer, model):
    """í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤."""
    device = get_optimal_device()

    # í…ìŠ¤íŠ¸ í† í°í™”
    inputs = tokenizer(text, return_tensors="pt").to(device)

    # ì˜ˆì¸¡ ìˆ˜í–‰
    with torch.no_grad():
        outputs = model(**inputs)
        predictions = outputs.logits.argmax(dim=-1)
        probabilities = torch.softmax(outputs.logits, dim=-1)

    # ê²°ê³¼ ë°˜í™˜
    sentiment = "ê¸ì •" if predictions[0] == 1 else "ë¶€ì •"
    confidence = probabilities[0][predictions[0]].item()

    return sentiment, confidence


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì €ì¥ëœ BERT ëª¨ë¸ë¡œ ê°ì • ë¶„ì„ ì‹œì‘!")
    print("=" * 50)

    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì°¾ê¸°
    models_dir = "models"
    if not os.path.exists(models_dir):
        print("âŒ models ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € 12_bert.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
        return

    # ëª¨ë¸ ëª©ë¡ í‘œì‹œ
    model_dirs = [d for d in os.listdir(
        models_dir) if os.path.isdir(os.path.join(models_dir, d))]
    if not model_dirs:
        print("âŒ ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € 12_bert.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
        return

    print("ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
    for i, model_dir in enumerate(model_dirs, 1):
        print(f"   [{i}] {model_dir}")

    # ëª¨ë¸ ì„ íƒ
    while True:
        try:
            choice = input(f"\nëª¨ë¸ ì„ íƒ (1-{len(model_dirs)}): ").strip()
            if choice == "":
                choice = "1"  # ê¸°ë³¸ê°’
            choice_idx = int(choice) - 1
            if 0 <= choice_idx < len(model_dirs):
                selected_model = model_dirs[choice_idx]
                break
            else:
                print(f"âŒ 1-{len(model_dirs)} ë²”ìœ„ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        except ValueError:
            print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    # ëª¨ë¸ ë¡œë“œ
    model_path = os.path.join(models_dir, selected_model)
    tokenizer, model = load_saved_model(model_path)

    if tokenizer is None or model is None:
        print("âŒ ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return

    # ê°ì • ë¶„ì„ ìˆ˜í–‰
    print(f"\nğŸ¯ ê°ì • ë¶„ì„ ì‹œì‘ (ëª¨ë¸: {selected_model})")
    print("=" * 50)

    # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤
    test_texts = [
        "This movie was absolutely fantastic! I loved every minute of it.",
        "Terrible acting and boring plot. Complete waste of time.",
        "The story was engaging and the characters were well-developed.",
        "I would not recommend this film to anyone.",
        "Amazing cinematography and outstanding performances!",
        "The movie was okay, nothing special but not bad either.",
        "This is the worst film I have ever seen in my life.",
        "I can watch this movie over and over again!"
    ]

    print("ğŸ“ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤:")
    for i, text in enumerate(test_texts, 1):
        sentiment, confidence = predict_sentiment(text, tokenizer, model)
        print(f"\n[{i}] {text}")
        print(f"    ì˜ˆì¸¡: {sentiment} (ì‹ ë¢°ë„: {confidence:.3f})")

    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    print(f"\nğŸ’¬ ì§ì ‘ í…ìŠ¤íŠ¸ ì…ë ¥í•˜ê¸°:")
    print("   (ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ì…ë ¥)")
    print("-" * 50)

    while True:
        user_text = input("\ní…ìŠ¤íŠ¸ ì…ë ¥: ").strip()

        if user_text.lower() in ['quit', 'exit', 'q']:
            break

        if not user_text:
            print("âŒ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            continue

        sentiment, confidence = predict_sentiment(user_text, tokenizer, model)
        print(f"   ì˜ˆì¸¡: {sentiment} (ì‹ ë¢°ë„: {confidence:.3f})")

    print("\nğŸ‰ ê°ì • ë¶„ì„ ì™„ë£Œ!")


if __name__ == "__main__":
    import torch
    main()
