#!/usr/bin/env python3
"""
ì›ë˜ ëª¨ë¸ê³¼ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì›ë³¸ DistilBERT ëª¨ë¸ê³¼ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„
ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤.
"""

import os
import time
import torch
from typing import List, Tuple, Dict
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from mps_utils import get_optimal_device, print_device_info


def load_models():
    """ì›ë³¸ ëª¨ë¸ê³¼ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    print("ğŸ“‚ ëª¨ë¸ ë¡œë”© ì¤‘...")

    # ë””ë°”ì´ìŠ¤ í™•ì¸
    device = get_optimal_device()
    print(f"   - ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

    # ì›ë³¸ ëª¨ë¸ ë¡œë“œ
    print("   - ì›ë³¸ DistilBERT ëª¨ë¸ ë¡œë”©...")
    original_tokenizer = AutoTokenizer.from_pretrained(
        "distilbert-base-uncased")
    original_model = AutoModelForSequenceClassification.from_pretrained(
        "distilbert-base-uncased")
    original_model = original_model.to(device)  # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™

    # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ì°¾ê¸°
    models_dir = "models"
    if not os.path.exists(models_dir):
        print("âŒ models ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € 12_bert.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
        return None, None, None, None

    model_dirs = [d for d in os.listdir(
        models_dir) if os.path.isdir(os.path.join(models_dir, d))]
    if not model_dirs:
        print("âŒ ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € 12_bert.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
        return None, None, None, None

    # ê°€ì¥ ìµœê·¼ ëª¨ë¸ ì„ íƒ (íŒŒì¼ ìˆ˜ì • ì‹œê°„ ê¸°ì¤€)
    model_dirs.sort(key=lambda x: os.path.getmtime(
        os.path.join(models_dir, x)), reverse=True)
    selected_model = model_dirs[0]

    print(f"   - íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¡œë”©: {selected_model}")
    fine_tuned_tokenizer = AutoTokenizer.from_pretrained(
        os.path.join(models_dir, selected_model))
    fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(
        os.path.join(models_dir, selected_model))
    fine_tuned_model = fine_tuned_model.to(device)  # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™

    print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    return original_tokenizer, original_model, fine_tuned_tokenizer, fine_tuned_model


def predict_sentiment(text: str, tokenizer, model, model_name: str) -> Tuple[str, float, float]:
    """í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤."""
    device = get_optimal_device()

    # í…ìŠ¤íŠ¸ í† í°í™”
    inputs = tokenizer(text, return_tensors="pt").to(device)

    # ì˜ˆì¸¡ ìˆ˜í–‰ (ëª¨ë¸ì€ ì´ë¯¸ ë””ë°”ì´ìŠ¤ì— ìˆìŒ)
    with torch.no_grad():
        outputs = model(**inputs)
        predictions = outputs.logits.argmax(dim=-1)
        probabilities = torch.softmax(outputs.logits, dim=-1)

    # ê²°ê³¼ ë°˜í™˜
    sentiment = "ê¸ì •" if predictions[0] == 1 else "ë¶€ì •"
    confidence = probabilities[0][predictions[0]].item()
    negative_prob = probabilities[0][0].item()
    positive_prob = probabilities[0][1].item()

    return sentiment, confidence, positive_prob


def get_test_sentences() -> List[Dict[str, any]]:
    """í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return [
        {
            "text": "This movie was absolutely fantastic! I loved every minute of it.",
            "expected": "ê¸ì •",
            "category": "ëª…í™•í•œ ê¸ì •"
        },
        {
            "text": "Terrible acting and boring plot. Complete waste of time.",
            "expected": "ë¶€ì •",
            "category": "ëª…í™•í•œ ë¶€ì •"
        },
        {
            "text": "The story was engaging and the characters were well-developed.",
            "expected": "ê¸ì •",
            "category": "ê¸ì •ì  í‰ê°€"
        },
        {
            "text": "I would not recommend this film to anyone.",
            "expected": "ë¶€ì •",
            "category": "ë¶€ì •ì  í‰ê°€"
        },
        {
            "text": "Amazing cinematography and outstanding performances!",
            "expected": "ê¸ì •",
            "category": "ê¸°ìˆ ì  ì¹­ì°¬"
        },
        {
            "text": "This is the worst film I have ever seen in my life.",
            "expected": "ë¶€ì •",
            "category": "ê·¹ë„ ë¶€ì •"
        },
        {
            "text": "The movie was okay, nothing special but not bad either.",
            "expected": "ì¤‘ë¦½",
            "category": "ì¤‘ë¦½ì "
        },
        {
            "text": "I can watch this movie over and over again!",
            "expected": "ê¸ì •",
            "category": "ê°•í•œ ê¸ì •"
        },
        {
            "text": "The acting was mediocre and the plot was predictable.",
            "expected": "ë¶€ì •",
            "category": "ë¶€ì •ì  ë¹„íŒ"
        },
        {
            "text": "This film exceeded all my expectations!",
            "expected": "ê¸ì •",
            "category": "ê¸°ëŒ€ ì´ˆê³¼"
        }
    ]


def compare_models():
    """ë‘ ëª¨ë¸ì„ ë¹„êµí•©ë‹ˆë‹¤."""
    print("ğŸ” ëª¨ë¸ ë¹„êµ ì‹œì‘!")
    print("=" * 60)

    # ë””ë°”ì´ìŠ¤ ì •ë³´ ì¶œë ¥
    print_device_info()

    # ëª¨ë¸ ë¡œë“œ
    original_tokenizer, original_model, fine_tuned_tokenizer, fine_tuned_model = load_models()

    if original_tokenizer is None:
        return

    # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤
    test_sentences = get_test_sentences()

    print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ ìˆ˜: {len(test_sentences)}ê°œ")
    print("=" * 60)

    # ê²°ê³¼ ì €ì¥
    results = []
    original_correct = 0
    fine_tuned_correct = 0

    for i, test_case in enumerate(test_sentences, 1):
        text = test_case["text"]
        expected = test_case["expected"]
        category = test_case["category"]

        print(f"\n[{i}] {category}")
        print(f"í…ìŠ¤íŠ¸: {text}")
        print(f"ì˜ˆìƒ: {expected}")

        # ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡
        orig_sentiment, orig_confidence, orig_positive_prob = predict_sentiment(
            text, original_tokenizer, original_model, "ì›ë³¸"
        )

        # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ì˜ˆì¸¡
        ft_sentiment, ft_confidence, ft_positive_prob = predict_sentiment(
            text, fine_tuned_tokenizer, fine_tuned_model, "íŒŒì¸íŠœë‹"
        )

        # ê²°ê³¼ ì¶œë ¥
        print(f"ì›ë³¸ ëª¨ë¸:     {orig_sentiment} (ì‹ ë¢°ë„: {
              orig_confidence:.3f}, ê¸ì •í™•ë¥ : {orig_positive_prob:.3f})")
        print(f"íŒŒì¸íŠœë‹ ëª¨ë¸: {ft_sentiment} (ì‹ ë¢°ë„: {
              ft_confidence:.3f}, ê¸ì •í™•ë¥ : {ft_positive_prob:.3f})")

        # ì •í™•ë„ ê³„ì‚° (ì¤‘ë¦½ ì œì™¸)
        if expected != "ì¤‘ë¦½":
            if orig_sentiment == expected:
                original_correct += 1
                print("   âœ… ì›ë³¸ ëª¨ë¸ ì •ë‹µ")
            else:
                print("   âŒ ì›ë³¸ ëª¨ë¸ ì˜¤ë‹µ")

            if ft_sentiment == expected:
                fine_tuned_correct += 1
                print("   âœ… íŒŒì¸íŠœë‹ ëª¨ë¸ ì •ë‹µ")
            else:
                print("   âŒ íŒŒì¸íŠœë‹ ëª¨ë¸ ì˜¤ë‹µ")

        # ê²°ê³¼ ì €ì¥
        results.append({
            "text": text,
            "expected": expected,
            "category": category,
            "original": {
                "sentiment": orig_sentiment,
                "confidence": orig_confidence,
                "positive_prob": orig_positive_prob
            },
            "fine_tuned": {
                "sentiment": ft_sentiment,
                "confidence": ft_confidence,
                "positive_prob": ft_positive_prob
            }
        })

    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š ë¹„êµ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)

    # ì¤‘ë¦½ ì œì™¸í•œ ë¬¸ì¥ ìˆ˜
    non_neutral_count = sum(1 for r in results if r["expected"] != "ì¤‘ë¦½")

    original_accuracy = original_correct / \
        non_neutral_count * 100 if non_neutral_count > 0 else 0
    fine_tuned_accuracy = fine_tuned_correct / \
        non_neutral_count * 100 if non_neutral_count > 0 else 0

    print(f"ì´ í…ŒìŠ¤íŠ¸ ë¬¸ì¥: {len(test_sentences)}ê°œ")
    print(f"ì¤‘ë¦½ ì œì™¸ ë¬¸ì¥: {non_neutral_count}ê°œ")
    print(f"ì›ë³¸ ëª¨ë¸ ì •í™•ë„: {
          original_correct}/{non_neutral_count} ({original_accuracy:.1f}%)")
    print(f"íŒŒì¸íŠœë‹ ëª¨ë¸ ì •í™•ë„: {
          fine_tuned_correct}/{non_neutral_count} ({fine_tuned_accuracy:.1f}%)")

    improvement = fine_tuned_accuracy - original_accuracy
    if improvement > 0:
        print(f"ğŸ‰ íŒŒì¸íŠœë‹ìœ¼ë¡œ {improvement:.1f}%p ê°œì„ !")
    elif improvement < 0:
        print(f"âš ï¸  íŒŒì¸íŠœë‹ìœ¼ë¡œ {abs(improvement):.1f}%p ê°ì†Œ")
    else:
        print("â– ì„±ëŠ¥ ë³€í™” ì—†ìŒ")

    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
    print(f"\nğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„:")
    print("-" * 40)

    categories = {}
    for result in results:
        cat = result["category"]
        if cat not in categories:
            categories[cat] = {"original": 0, "fine_tuned": 0, "total": 0}

        if result["expected"] != "ì¤‘ë¦½":
            categories[cat]["total"] += 1
            if result["original"]["sentiment"] == result["expected"]:
                categories[cat]["original"] += 1
            if result["fine_tuned"]["sentiment"] == result["expected"]:
                categories[cat]["fine_tuned"] += 1

    for cat, stats in categories.items():
        if stats["total"] > 0:
            orig_acc = stats["original"] / stats["total"] * 100
            ft_acc = stats["fine_tuned"] / stats["total"] * 100
            print(f"{cat:12}: ì›ë³¸ {orig_acc:5.1f}% â†’ íŒŒì¸íŠœë‹ {
                  ft_acc:5.1f}% (ê°œì„ : {ft_acc-orig_acc:+5.1f}%p)")

    print("\nğŸ‰ ëª¨ë¸ ë¹„êµ ì™„ë£Œ!")


def interactive_comparison():
    """ëŒ€í™”í˜• ëª¨ë¸ ë¹„êµë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    print("ğŸ’¬ ëŒ€í™”í˜• ëª¨ë¸ ë¹„êµ")
    print("=" * 30)
    print("ì§ì ‘ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì—¬ ë‘ ëª¨ë¸ì„ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ì…ë ¥")
    print("-" * 30)

    # ëª¨ë¸ ë¡œë“œ
    original_tokenizer, original_model, fine_tuned_tokenizer, fine_tuned_model = load_models()

    if original_tokenizer is None:
        return

    while True:
        user_text = input("\ní…ìŠ¤íŠ¸ ì…ë ¥: ").strip()

        if user_text.lower() in ['quit', 'exit', 'q']:
            break

        if not user_text:
            print("âŒ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            continue

        print(f"\ní…ìŠ¤íŠ¸: {user_text}")

        # ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡
        orig_sentiment, orig_confidence, orig_positive_prob = predict_sentiment(
            user_text, original_tokenizer, original_model, "ì›ë³¸"
        )

        # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ì˜ˆì¸¡
        ft_sentiment, ft_confidence, ft_positive_prob = predict_sentiment(
            user_text, fine_tuned_tokenizer, fine_tuned_model, "íŒŒì¸íŠœë‹"
        )

        print(f"ì›ë³¸ ëª¨ë¸:     {orig_sentiment} (ì‹ ë¢°ë„: {
              orig_confidence:.3f}, ê¸ì •í™•ë¥ : {orig_positive_prob:.3f})")
        print(f"íŒŒì¸íŠœë‹ ëª¨ë¸: {ft_sentiment} (ì‹ ë¢°ë„: {
              ft_confidence:.3f}, ê¸ì •í™•ë¥ : {ft_positive_prob:.3f})")

        # ê²°ê³¼ ë¹„êµ
        if orig_sentiment == ft_sentiment:
            print("   â– ë‘ ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ë™ì¼í•©ë‹ˆë‹¤.")
        else:
            print("   âš¡ ë‘ ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ë‹¤ë¦…ë‹ˆë‹¤!")

    print("\nğŸ‰ ëŒ€í™”í˜• ë¹„êµ ì™„ë£Œ!")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì›ë³¸ ëª¨ë¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ ë¹„êµ")
    print("=" * 50)

    while True:
        print("\nğŸ¯ ë¹„êµ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print("   1. ìë™ í…ŒìŠ¤íŠ¸ (10ê°œ ë¬¸ì¥)")
        print("   2. ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸")
        print("   3. ì¢…ë£Œ")

        choice = input("\nì„ íƒ (1-3): ").strip()

        if choice == "1":
            compare_models()
        elif choice == "2":
            interactive_comparison()
        elif choice == "3":
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        else:
            print("âŒ 1-3 ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
