#!/usr/bin/env python3
"""
BERT Fine-tuning for IMDB Sentiment Analysis - M4 Pro ìµœì í™” ë²„ì „
48GB RAMì„ í™œìš©í•œ ê³ ì„±ëŠ¥ íŒŒì¸íŠœë‹

ì£¼ìš” ìµœì í™” í¬ì¸íŠ¸:
1. ëŒ€í­ ì¦ê°€ëœ ë°°ì¹˜ í¬ê¸° (16â†’128, 32â†’256, 64â†’512)
2. Mixed Precision Training (AMP) í™œì„±í™”
3. Gradient Accumulation í™œìš©
4. DataLoader ìµœì í™”
5. ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì˜µí‹°ë§ˆì´ì €
6. M4 Pro íŠ¹í™” ì„¤ì •
"""

import os
import time
from typing import Dict, Any, Optional

from datasets import load_dataset, DatasetDict
from sklearn.metrics import accuracy_score
from tqdm.auto import tqdm
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    Trainer,
    TrainingArguments,
    DataCollatorWithPadding,
)

# MPS ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ import
from mps_utils import warm_up_mps, check_mps_availability, get_optimal_device, print_device_info


def setup_memory_optimization():
    """MPS ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •"""
    print("ğŸ”§ MPS ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì • ì¤‘...")

    # MPS ë©”ëª¨ë¦¬ í• ë‹¹ ì œí•œ ì„¤ì •ì„ ì œê±°í•˜ê³  ê¸°ë³¸ê°’ ì‚¬ìš©
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì´ ì˜¤ë¥˜ë¥¼ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì œê±°

    # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•œ ì¶”ê°€ ì„¤ì •ë§Œ ìœ ì§€
    os.environ["PYTORCH_MPS_ALLOCATOR"] = "native"

    print("   - PYTORCH_MPS_ALLOCATOR=native ì„¤ì •")
    print("   - MPS ê¸°ë³¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‚¬ìš©")
    print("âœ… ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì • ì™„ë£Œ!")


def check_label_distribution(dataset, dataset_name="ìƒ˜í”Œ"):
    """ë°ì´í„°ì…‹ì˜ ë ˆì´ë¸” ë¶„í¬ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    print(f"\nğŸ“Š {dataset_name} ë ˆì´ë¸” ë¶„í¬ í™•ì¸:")
    print("=" * 50)

    # í›ˆë ¨ ë°ì´í„° ë ˆì´ë¸” ë¶„í¬
    train_labels = [dataset["train"][i]["label"]
                    for i in range(len(dataset["train"]))]
    train_positive = sum(1 for label in train_labels if label == 1)
    train_negative = sum(1 for label in train_labels if label == 0)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë ˆì´ë¸” ë¶„í¬
    test_labels = [dataset["test"][i]["label"]
                   for i in range(len(dataset["test"]))]
    test_positive = sum(1 for label in test_labels if label == 1)
    test_negative = sum(1 for label in test_labels if label == 0)

    print(f"í›ˆë ¨ ë°ì´í„°: ê¸ì • {train_positive}ê°œ, ë¶€ì • {train_negative}ê°œ")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: ê¸ì • {test_positive}ê°œ, ë¶€ì • {test_negative}ê°œ")
    print(f"ì „ì²´: ê¸ì • {train_positive +
          test_positive}ê°œ, ë¶€ì • {train_negative + test_negative}ê°œ")

    return {
        'train_positive': train_positive,
        'train_negative': train_negative,
        'test_positive': test_positive,
        'test_negative': test_negative,
    }


def get_sample_size(total_size):
    """ì‚¬ìš©ìë¡œë¶€í„° ìƒ˜í”Œ í¬ê¸°ë¥¼ ì…ë ¥ë°›ìŠµë‹ˆë‹¤."""
    print(f"\nğŸ“Š ì „ì²´ IMDB ë°ì´í„°ì…‹: {total_size:,}ê°œ")
    print("=" * 50)
    print("ğŸ¯ í•™ìŠµì— ì‚¬ìš©í•  ìƒ˜í”Œ í¬ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("   - ì—”í„°: ê¸°ë³¸ê°’ 1000ê°œ ì‚¬ìš©")
    print("   - 0: ì „ì²´ ë°ì´í„° ì‚¬ìš©")
    print("   - ìˆ«ì: í•´ë‹¹ ê°œìˆ˜ë§Œí¼ ìƒ˜í”Œ ì‚¬ìš©")
    print("=" * 50)

    while True:
        try:
            user_input = input("ìƒ˜í”Œ í¬ê¸° ì…ë ¥ (ì—”í„°=1000, 0=ì „ì²´): ").strip()

            if user_input == "":
                return 1000  # ê¸°ë³¸ê°’
            elif user_input == "0":
                return total_size  # ì „ì²´ ë°ì´í„°
            else:
                sample_size = int(user_input)
                if sample_size < 0:
                    print("âŒ ìŒìˆ˜ëŠ” ì…ë ¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.")
                    continue
                elif sample_size > total_size:
                    print(
                        f"âŒ ì „ì²´ ë°ì´í„°({total_size:,}ê°œ)ë³´ë‹¤ í° ìˆ˜ëŠ” ì…ë ¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.")
                    continue
                return sample_size
        except ValueError:
            print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì—”í„°ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
            continue


def get_checkpoint_info():
    """ì²´í¬í¬ì¸íŠ¸ ê´€ë ¨ ì •ë³´ë¥¼ ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ë°›ìŠµë‹ˆë‹¤."""
    print("\nğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì„¤ì •:")
    print("=" * 40)
    print("ğŸ¯ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("   - ì—”í„°: ìë™ ì €ì¥ (ì—í¬í¬ë§ˆë‹¤)")
    print("   - 0: ì €ì¥ ì•ˆí•¨")
    print("   - ìˆ«ì: N ì—í¬í¬ë§ˆë‹¤ ì €ì¥")
    print("=" * 40)

    while True:
        try:
            user_input = input(
                "ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì£¼ê¸° (ì—”í„°=ìë™, 0=ì €ì¥ì•ˆí•¨, ìˆ«ì=Nì—í¬í¬ë§ˆë‹¤): ").strip()

            if user_input == "":
                return "auto"  # ìë™ ì €ì¥
            elif user_input == "0":
                return "no"  # ì €ì¥ ì•ˆí•¨
            else:
                save_every = int(user_input)
                if save_every < 1:
                    print("âŒ 1 ì´ìƒì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                    continue
                return save_every
        except ValueError:
            print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì—”í„°ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
            continue


def find_latest_checkpoint(output_dir: str) -> Optional[str]:
    """ê°€ì¥ ìµœê·¼ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    if not os.path.exists(output_dir):
        return None

    checkpoints = []
    for item in os.listdir(output_dir):
        if item.startswith("checkpoint-"):
            checkpoints.append(item)

    if not checkpoints:
        return None

    # ì²´í¬í¬ì¸íŠ¸ ë²ˆí˜¸ë¡œ ì •ë ¬
    checkpoints.sort(key=lambda x: int(x.split("-")[1]))
    latest_checkpoint = os.path.join(output_dir, checkpoints[-1])

    print(f"ğŸ” ë°œê²¬ëœ ì²´í¬í¬ì¸íŠ¸: {len(checkpoints)}ê°œ")
    print(f"   ìµœì‹  ì²´í¬í¬ì¸íŠ¸: {latest_checkpoint}")

    return latest_checkpoint


def ask_resume_training() -> bool:
    """ì´ì–´ì„œ í•™ìŠµí• ì§€ ì‚¬ìš©ìì—ê²Œ ë¬»ìŠµë‹ˆë‹¤."""
    print("\nğŸ”„ ì´ì–´ì„œ í•™ìŠµí•˜ê¸°:")
    print("=" * 30)
    print("ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("   - ì—”í„°: ì´ì–´ì„œ í•™ìŠµ")
    print("   - n: ìƒˆë¡œ ì‹œì‘")
    print("=" * 30)

    while True:
        user_input = input("ì´ì–´ì„œ í•™ìŠµí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ì—”í„°=ì˜ˆ, n=ì•„ë‹ˆì˜¤): ").strip().lower()

        if user_input == "" or user_input == "y" or user_input == "yes":
            return True
        elif user_input == "n" or user_input == "no":
            return False
        else:
            print("âŒ ì—”í„° ë˜ëŠ” 'n'ì„ ì…ë ¥í•˜ì„¸ìš”.")
            continue


def load_imdb_dataset(full_dataset, total_size, sample_size=None) -> DatasetDict:
    """IMDB ë°ì´í„°ì…‹ì„ ì§€ì •ëœ í¬ê¸°ë¡œ ìƒ˜í”Œë§í•˜ì—¬ 8:2ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""
    print("ë°ì´í„°ì…‹ ìƒ˜í”Œë§ ì‹œì‘...")
    start_time = time.time()

    # ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ìƒ˜í”Œ í¬ê¸° ê²°ì •
    if sample_size is None:
        sample_size = get_sample_size(total_size)

    print(f"\nğŸ“Š ì„ íƒëœ ìƒ˜í”Œ í¬ê¸°: {sample_size:,}ê°œ")
    if sample_size == total_size:
        print("   - ì „ì²´ ë°ì´í„° ì‚¬ìš©")
    else:
        print(f"   - ì „ì²´ì˜ {sample_size/total_size*100:.2f}% ì‚¬ìš©")

    # tqdmì„ ì‚¬ìš©í•œ ë” ìì„¸í•œ í”„ë¡œê·¸ë ˆìŠ¤ë°”
    with tqdm(total=100, desc="ìƒ˜í”Œ ë°ì´í„° ì²˜ë¦¬", unit="%",
              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]') as pbar:

        if sample_size == total_size:
            # ì „ì²´ ë°ì´í„° ì‚¬ìš©
            dataset = full_dataset["train"].train_test_split(test_size=0.2)
        else:
            # ì§€ì •ëœ í¬ê¸°ë§Œí¼ ìƒ˜í”Œë§
            dataset = full_dataset["train"].select(
                range(sample_size)).train_test_split(test_size=0.2)

        # í”„ë¡œê·¸ë ˆìŠ¤ë°” ì™„ë£Œ
        pbar.n = 100
        pbar.refresh()

    end_time = time.time()
    print(f"âœ… ìƒ˜í”Œ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ! ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    print(f"ğŸ“ ìºì‹œ ìœ„ì¹˜: ./data_cache")
    print(f"ğŸ“Š ì‚¬ìš©ëœ ìƒ˜í”Œ: {len(dataset['train']) + len(dataset['test'])}ê°œ")
    print(f"ğŸ“Š í›ˆë ¨ ìƒ˜í”Œ: {len(dataset['train'])}ê°œ, í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {
          len(dataset['test'])}ê°œ")

    # ìƒ˜í”Œ ë°ì´í„° ë ˆì´ë¸” ë¶„í¬ í™•ì¸
    sample_distribution = check_label_distribution(dataset, "ìƒ˜í”Œ")

    return dataset


def load_full_dataset_info():
    """ì „ì²´ IMDB ë°ì´í„°ì…‹ ì •ë³´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    print("ğŸ” ì „ì²´ IMDB ë°ì´í„°ì…‹ í¬ê¸° í™•ì¸ ì¤‘...")
    full_dataset = load_dataset("imdb", cache_dir="./data_cache")
    total_train = len(full_dataset["train"])
    total_test = len(full_dataset["test"])
    total_size = total_train + total_test

    print(f"ğŸ“Š ì „ì²´ IMDB ë°ì´í„°ì…‹: {total_size:,}ê°œ")
    print(f"   - í›ˆë ¨ ë°ì´í„°: {total_train:,}ê°œ")
    print(f"   - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {total_test:,}ê°œ")

    return full_dataset, total_train, total_test, total_size


def load_model_and_tokenizer():
    """ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    print("\n=== ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”© ===")

    # MPS warm-up ë¨¼ì € ìˆ˜í–‰
    warm_up_mps()

    tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
    model = AutoModelForSequenceClassification.from_pretrained(
        "distilbert-base-uncased")

    print("âœ… ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”© ì™„ë£Œ!")
    return tokenizer, model


def preprocess_data(dataset: DatasetDict, tokenizer) -> DatasetDict:
    """ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    print("\n=== ë°ì´í„° ì „ì²˜ë¦¬ ===")

    def tokenize(batch):
        """í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•©ë‹ˆë‹¤ (íŒ¨ë”©ì€ DataCollatorì—ì„œ ì²˜ë¦¬)."""
        return tokenizer(batch["text"], truncation=True, max_length=256)  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ 256ìœ¼ë¡œ ì œí•œ

    dataset = dataset.map(tokenize, batched=True)
    print("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
    return dataset


def setup_trainer(model, dataset: DatasetDict, tokenizer, checkpoint_config="auto", resume_from_checkpoint=None) -> Trainer:
    """M4 Pro ìµœì í™”ëœ í›ˆë ¨ ì„¤ì • ë° Trainerë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
    print("\n=== M4 Pro ìµœì í™” í›ˆë ¨ ì„¤ì • êµ¬ì„± ===")

    def compute_metrics(eval_pred):
        """í‰ê°€ ì˜ˆì¸¡ ê²°ê³¼ì˜ ì •í™•ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        logits, labels = eval_pred
        predictions = logits.argmax(axis=-1)
        acc = accuracy_score(labels, predictions)
        return {"accuracy": acc}

    # ë°ì´í„°ì…‹ í¬ê¸°ì— ë”°ë¥¸ ë™ì  ì„¤ì •
    train_size = len(dataset["train"])
    total_samples = train_size + len(dataset["test"])

    print(f"ğŸ“Š ë°ì´í„°ì…‹ í¬ê¸°: {total_samples:,}ê°œ (í›ˆë ¨: {train_size:,}ê°œ)")

    # M4 Pro + 48GB RAM ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì •
    if total_samples <= 1000:
        # ì†Œê·œëª¨ ë°ì´í„°ì…‹ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë°°ì¹˜ í¬ê¸°
        batch_size = 32  # ë©”ëª¨ë¦¬ ì•ˆì •ì„±ì„ ìœ„í•´ ì¡°ì •
        gradient_accumulation_steps = 8  # ì‹¤ì œ ë°°ì¹˜ í¬ê¸° = 256
        num_epochs = 15
        logging_steps = 5
        print("   - ì†Œê·œëª¨ ë°ì´í„°ì…‹ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì • ì ìš©")
        print(
            f"   - ë°°ì¹˜ í¬ê¸°: {batch_size} (Gradient Accumulation: {gradient_accumulation_steps})")
    elif total_samples <= 10000:
        # ì¤‘ê°„ ê·œëª¨ ë°ì´í„°ì…‹ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë°°ì¹˜ í¬ê¸°
        batch_size = 64  # ë©”ëª¨ë¦¬ ì•ˆì •ì„±ì„ ìœ„í•´ ì¡°ì •
        gradient_accumulation_steps = 8  # ì‹¤ì œ ë°°ì¹˜ í¬ê¸° = 512
        num_epochs = 10
        logging_steps = 10
        print("   - ì¤‘ê°„ ê·œëª¨ ë°ì´í„°ì…‹ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì • ì ìš©")
        print(
            f"   - ë°°ì¹˜ í¬ê¸°: {batch_size} (Gradient Accumulation: {gradient_accumulation_steps})")
    else:
        # ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë°°ì¹˜ í¬ê¸°
        batch_size = 128  # ë©”ëª¨ë¦¬ ì•ˆì •ì„±ì„ ìœ„í•´ ì¡°ì •
        gradient_accumulation_steps = 8  # ì‹¤ì œ ë°°ì¹˜ í¬ê¸° = 1024
        num_epochs = 5
        logging_steps = 50
        print("   - ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì • ì ìš©")
        print(
            f"   - ë°°ì¹˜ í¬ê¸°: {batch_size} (Gradient Accumulation: {gradient_accumulation_steps})")

    # ì²´í¬í¬ì¸íŠ¸ ì„¤ì •
    output_dir = "checkpoints"
    save_strategy = "no"
    save_steps = None

    if checkpoint_config == "auto":
        save_strategy = "epoch"
        print("   - ì²´í¬í¬ì¸íŠ¸: ì—í¬í¬ë§ˆë‹¤ ìë™ ì €ì¥")
    elif checkpoint_config == "no":
        print("   - ì²´í¬í¬ì¸íŠ¸: ì €ì¥ ì•ˆí•¨")
    elif isinstance(checkpoint_config, int):
        save_strategy = "steps"
        save_steps = checkpoint_config * \
            (train_size // (batch_size * gradient_accumulation_steps))
        print(f"   - ì²´í¬í¬ì¸íŠ¸: {checkpoint_config} ì—í¬í¬ë§ˆë‹¤ ì €ì¥ (ë§¤ {save_steps} ìŠ¤í…)")

    # M4 Pro ìµœì í™”ëœ TrainingArguments
    args = TrainingArguments(
        output_dir=output_dir,
        per_device_train_batch_size=batch_size,
        per_device_eval_batch_size=batch_size,
        gradient_accumulation_steps=gradient_accumulation_steps,
        num_train_epochs=num_epochs,
        report_to="none",  # ì™¸ë¶€ ë¡œê¹…íˆ´ ë¹„í™œì„±í™”
        logging_steps=logging_steps,

        # M4 Pro ìµœì í™” ì„¤ì •
        dataloader_pin_memory=False,  # MPSì—ì„œëŠ” pin_memory ë¹„í™œì„±í™” ê¶Œì¥
        dataloader_num_workers=0,     # MPSì—ì„œëŠ” ë©€í‹°í”„ë¡œì„¸ì‹± ë¹„í™œì„±í™” ê¶Œì¥
        dataloader_drop_last=True,    # ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ ë°°ì¹˜ ì œê±°

        # Mixed Precision Training (AMP) - M4 Pro Neural Engine í™œìš©
        # MPSì—ì„œëŠ” fp16ì´ ì§€ì›ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ bf16 ì‚¬ìš©
        bf16=True,  # M4 Pro MPSì—ì„œ ì§€ì›ë˜ëŠ” mixed precision

        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì„¤ì •
        max_grad_norm=1.0,  # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì•ˆì •ì„± í–¥ìƒ

        # MPS í˜¸í™˜ ì˜µí‹°ë§ˆì´ì €
        optim="adamw_torch",  # MPSì—ì„œ ì•ˆì •ì ì¸ AdamW

        # í•™ìŠµë¥  ë° ì •ê·œí™”
        learning_rate=2e-5,
        weight_decay=0.01,
        warmup_ratio=0.1,  # ì›Œë°ì—… ì¶”ê°€

        # ì²´í¬í¬ì¸íŠ¸ ì„¤ì •
        save_strategy=save_strategy,
        save_steps=save_steps,
        eval_strategy="no",  # í‰ê°€ ë¹„í™œì„±í™”ë¡œ ì†ë„ í–¥ìƒ
        load_best_model_at_end=False,
        save_total_limit=3,

        # M4 Pro íŠ¹í™” ì„¤ì •
        dataloader_prefetch_factor=None,  # MPSì—ì„œëŠ” prefetch ë¹„í™œì„±í™”
        remove_unused_columns=True,       # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì œê±°
        label_smoothing_factor=0.1,       # ë¼ë²¨ ìŠ¤ë¬´ë”©ìœ¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
    )

    # DataCollator ì„¤ì • (ë™ì  íŒ¨ë”©)
    data_collator = DataCollatorWithPadding(
        tokenizer=tokenizer,
        padding=True,
        max_length=256,  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ 256ìœ¼ë¡œ ì œí•œ
        return_tensors="pt"
    )

    trainer = Trainer(
        model=model,
        args=args,
        train_dataset=dataset["train"],
        eval_dataset=dataset["test"],
        compute_metrics=compute_metrics,
        tokenizer=tokenizer,
        data_collator=data_collator,  # ë™ì  íŒ¨ë”©ì„ ìœ„í•œ DataCollator
    )

    # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ì–´ì„œ í•™ìŠµ
    if resume_from_checkpoint:
        print(f"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ì–´ì„œ í•™ìŠµ: {resume_from_checkpoint}")
        trainer.train(resume_from_checkpoint=resume_from_checkpoint)
        return trainer

    print("âœ… M4 Pro ìµœì í™” í›ˆë ¨ ì„¤ì • ì™„ë£Œ!")
    print(f"ğŸš€ M4 Pro + 48GB RAM ìµœì í™” ì„¤ì • ì ìš©ë¨!")
    print(f"   - ì‹¤ì œ ë°°ì¹˜ í¬ê¸°: {batch_size * gradient_accumulation_steps}")
    print(f"   - Mixed Precision: bf16=True (MPS í˜¸í™˜)")
    print(f"   - DataLoader ìµœì í™”: MPS í˜¸í™˜ ì„¤ì •")
    print(f"   - ì˜µí‹°ë§ˆì´ì €: adamw_torch (MPS í˜¸í™˜)")

    return trainer


def train_model(trainer: Trainer) -> Dict[str, Any]:
    """ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤."""
    print("\n=== ëª¨ë¸ í›ˆë ¨ ===")
    print("í›ˆë ¨ ì‹œì‘...")

    train_result = trainer.train()

    print("í›ˆë ¨ ì™„ë£Œ!")
    print(f"í›ˆë ¨ ê²°ê³¼: {train_result}")

    return train_result


def save_final_model(trainer: Trainer, model_name: str = "fine_tuned_bert"):
    """íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì„ ë¡œì»¬ì— ì €ì¥í•©ë‹ˆë‹¤."""
    print(f"\nğŸ’¾ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ì €ì¥ ì¤‘...")

    # ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    model_dir = f"models/{model_name}"
    os.makedirs(model_dir, exist_ok=True)

    # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì €ì¥
    trainer.save_model(model_dir)

    # í† í¬ë‚˜ì´ì € ì €ì¥
    if hasattr(trainer, 'tokenizer') and trainer.tokenizer is not None:
        trainer.tokenizer.save_pretrained(model_dir)
    elif hasattr(trainer, 'processing_class') and trainer.processing_class is not None:
        trainer.processing_class.save_pretrained(model_dir)
    else:
        print("âš ï¸  í† í¬ë‚˜ì´ì €ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ë§Œ ì €ì¥ë©ë‹ˆë‹¤.")

    print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
    print(f"   ğŸ“ ì €ì¥ ìœ„ì¹˜: {model_dir}/")

    return model_dir


def load_saved_model(model_path: str):
    """ì €ì¥ëœ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    print(f"ğŸ“‚ ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")

    try:
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSequenceClassification.from_pretrained(model_path)

        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        return tokenizer, model
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None


def test_predictions(tokenizer, model):
    """í•™ìŠµëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    print("\n=== ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ===")

    # ìµœì  ë””ë°”ì´ìŠ¤ í™•ì¸
    device = get_optimal_device()
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

    # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤
    test_texts = [
        "I would put this at the top of the list of films in the category of unwatchable trash.",
        "I can watch this all day.",
        "This movie is absolutely fantastic!",
        "Terrible acting and boring plot."
    ]

    for text in test_texts:
        print(f"\ní…ìŠ¤íŠ¸: {text}")

        # ì…ë ¥ëœ ë¬¸ì¥ì„ í† í°í™”í•˜ì—¬ ì ì ˆí•œ ë””ë°”ì´ìŠ¤ì— ì „ë‹¬
        inputs = tokenizer(text, return_tensors="pt").to(device)

        outputs = model(**inputs)
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¸ë±ìŠ¤ë¥¼ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì‚¬ìš©
        predictions = outputs.logits.argmax(dim=-1)

        print(f"ì˜ˆì¸¡ ë ˆì´ë¸”: {predictions[0]}")
        print(f"ì˜ˆì¸¡ í™•ë¥ : {outputs.logits[0][predictions[0]].item()}")
        print("ê¸ì •" if predictions[0] == 1 else "ë¶€ì •")

        # ë¡œì§“ ê°’ ì¶œë ¥
        print(f"ë¡œì§“ ê°’: {outputs.logits[0]}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ BERT Fine-tuning for IMDB Sentiment Analysis - M4 Pro ìµœì í™” ë²„ì „!")
    print("=" * 80)
    print("ğŸ”¥ M4 Pro + 48GB RAM ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì • ì ìš©")
    print("=" * 80)

    # 0. ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
    setup_memory_optimization()

    # 1. ë””ë°”ì´ìŠ¤ ì •ë³´ ì¶œë ¥
    print_device_info()

    # 2. ì „ì²´ ë°ì´í„°ì…‹ ì •ë³´ ë¡œë“œ
    full_dataset, total_train, total_test, total_size = load_full_dataset_info()

    # 3. ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ
    dataset = load_imdb_dataset(full_dataset, total_size)

    # 4. ì²´í¬í¬ì¸íŠ¸ ì„¤ì •
    checkpoint_config = get_checkpoint_info()

    # 5. ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ í™•ì¸
    output_dir = "checkpoints"
    latest_checkpoint = find_latest_checkpoint(output_dir)
    resume_from_checkpoint = None

    if latest_checkpoint:
        if ask_resume_training():
            resume_from_checkpoint = latest_checkpoint
        else:
            print("ğŸ”„ ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤. ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ëŠ” ë¬´ì‹œë©ë‹ˆë‹¤.")

    # 6. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer, model = load_model_and_tokenizer()

    # 7. ë°ì´í„° ì „ì²˜ë¦¬
    dataset = preprocess_data(dataset, tokenizer)

    # 8. M4 Pro ë©”ëª¨ë¦¬ íš¨ìœ¨ì  í›ˆë ¨ ì„¤ì •
    trainer = setup_trainer(
        model, dataset, tokenizer, checkpoint_config, resume_from_checkpoint)

    # 9. ëª¨ë¸ í›ˆë ¨
    if not resume_from_checkpoint:
        train_result = train_model(trainer)
    else:
        print("âœ… ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ì–´ì„œ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    # 10. íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ì €ì¥
    model_name = f"bert_imdb_{
        len(dataset['train']) + len(dataset['test'])}samples_m4pro_memory_optimized"
    saved_model_dir = save_final_model(trainer, model_name)

    # 11. ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    test_predictions(tokenizer, model)

    print("\n" + "=" * 80)
    print("ğŸ‰ M4 Pro ìµœì í™” ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì™„ë£Œ!")
    print("ğŸ”¥ ì£¼ìš” ìµœì í™” ì‚¬í•­:")
    print("   - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë°°ì¹˜ í¬ê¸° (32/64/128)")
    print("   - Mixed Precision Training (bf16) í™œì„±í™”")
    print("   - Gradient Accumulationìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ")
    print("   - í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (256 í† í°)")
    print("   - MPS ê¸°ë³¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‚¬ìš©")
    print("   - M4 Pro Neural Engine í™œìš©")
    if checkpoint_config != "no":
        print(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ìœ„ì¹˜: {output_dir}/")
    print(f"ğŸ’¾ ìµœì¢… ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {saved_model_dir}/")


if __name__ == "__main__":
    main()
